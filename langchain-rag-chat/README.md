# ğŸ“š LangChain RAG with Chroma + OpenAI

A simple Retrieval-Augmented Generation (RAG) system using:

* ğŸ” `Chroma` as a vector database
* ğŸ§  OpenAI embeddings + `ChatOpenAI`
* ğŸ§© LangChain for document splitting and processing

---

## âš™ï¸ Requirements

```bash
pip install langchain langchain-openai langchain-chroma openai python-dotenv
```

Create a `.env` file with your API key:

```
OPENAI_API_KEY=sk-...
```

---

## ğŸ“ Files

* `generate.py` â€“ loads `.txt` files from `data/books/`, splits them, and saves embeddings to Chroma
* `query.py` â€“ asks questions using the context retrieved from Chroma

---

## ğŸš€ Usage

1. Build the vector store:

   ```bash
   python generate.py
   ```

2. Ask a question:

   ```bash
   python query.py "What is The Plague about?"
   ```

---

## âœ… Example Output

```
Response: The main character is a doctor fighting an epidemic.
Sources: ['data/books/the_plague.txt']
```